{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a067b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Before your go ----\n",
    "# 1. Rename Assignment-03-###.ipynb where ### is your student ID.\n",
    "# 2. The deadline of Assignment-03 is 23:59pm, 06-05-2024\n",
    "\n",
    "\n",
    "# --- Explore HMM POS Taggers using Brown corpus ---\n",
    "# In this assignment, you will explore three taggers for a Brown corpus.\n",
    "# import your packages here\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bb55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 --- Load and explore your data ---\n",
    "# 1). load train/test samples from Brown corpus files, brown-train.txt, brown-test.txt.\n",
    "# 2). load all 12 tags from brown-tag.txt and print it out\n",
    "# 3). counting how many sentences and words in both train and test datasets.\n",
    "# 4). for each tag, counting how many words in train and test. e.g, tag1: [count_tr, count_te]\n",
    "\n",
    "\n",
    "def build_sent_word_dict(filename: str):\n",
    "    lines = open(filename, \"r\").readlines()\n",
    "    num_sents = 0\n",
    "    num_words = 0\n",
    "    sent_word_dict = []\n",
    "    word_dict = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"b100-\") and word_dict != []:\n",
    "            num_sents += 1\n",
    "            sent_word_dict.append(word_dict)\n",
    "            word_dict = []\n",
    "        elif len(line.split()) == 2:\n",
    "            num_words += 1\n",
    "            word, tag = line.split()\n",
    "            word_dict.append({\"word\": word, \"tag\": tag})\n",
    "    sent_word_dict.append(word_dict)\n",
    "    return sent_word_dict, num_sents + 1, num_words\n",
    "\n",
    "\n",
    "train_sents, train_num_sents, train_num_words = build_sent_word_dict(\"brown-train.txt\")\n",
    "test_sents, test_num_sents, test_num_words = build_sent_word_dict(\"brown-test.txt\")\n",
    "TAGS = open(\"brown-tag.txt\", \"r\").readlines()\n",
    "for i in range(len(TAGS)):\n",
    "    TAGS[i] = TAGS[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18af0d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train: 45800\n",
      "Number of sentences in test: 11540\n",
      "Number of words in train: 928327\n",
      "Number of words in test: 232865\n",
      "Tag: .   \t Count in train: 117723\t Count in test: 29842\n",
      "Tag: ADJ   \t Count in train: 66985\t Count in test: 16736\n",
      "Tag: ADP   \t Count in train: 115752\t Count in test: 29014\n",
      "Tag: ADV   \t Count in train: 44765\t Count in test: 11474\n",
      "Tag: CONJ   \t Count in train: 30455\t Count in test: 7696\n",
      "Tag: DET   \t Count in train: 109418\t Count in test: 27601\n",
      "Tag: NOUN   \t Count in train: 220451\t Count in test: 55107\n",
      "Tag: NUM   \t Count in train: 11921\t Count in test: 2953\n",
      "Tag: PRON   \t Count in train: 39657\t Count in test: 9677\n",
      "Tag: PRT   \t Count in train: 23889\t Count in test: 5940\n",
      "Tag: VERB   \t Count in train: 146199\t Count in test: 36551\n",
      "Tag: X   \t Count in train: 1112\t Count in test: 274\n"
     ]
    }
   ],
   "source": [
    "def get_tag_count(sents: list, tag: str):\n",
    "    count = 0\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            if word[\"tag\"] == tag:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "print(\"Number of sentences in train:\", train_num_sents)\n",
    "print(\"Number of sentences in test:\", test_num_sents)\n",
    "print(\"Number of words in train:\", train_num_words)\n",
    "print(\"Number of words in test:\", test_num_words)\n",
    "\n",
    "major_tag = \"\"\n",
    "major_count = 0\n",
    "for tag in TAGS:\n",
    "    count_tr = get_tag_count(train_sents, tag)\n",
    "    count_te = get_tag_count(test_sents, tag)\n",
    "    if count_tr > major_count:\n",
    "        major_count = count_tr\n",
    "        major_tag = tag\n",
    "    print(f\"Tag: {tag}   \\t Count in train: {count_tr}\\t Count in test: {count_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d633df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: 0.9571961173164197\n",
      "Accuracy on test: 0.945187125587787\n"
     ]
    }
   ],
   "source": [
    "# Task 2 --- Method 1: Build a baseline method, namely, the most frequent tagger ---\n",
    "#     If you can recall, we introduced a strong baseline method (See Dan's book in\n",
    "# https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf Page 164.),\n",
    "#     where we label each word by using the most frequent-used tag associated with it.\n",
    "# 1). find the most frequent class label for each word in the training data.\n",
    "#     For example, {tr_word_1:tag_1,tr_word_2:tag_2,...}\n",
    "# 2). use your built method to predict tags for both train and test datasets.\n",
    "#     You should print out two values: the accuracies of train and test samples.\n",
    "#     You would expect that the accuracy on train will be > 9.0 (but never = 1.0) and higher than on test.\n",
    "\n",
    "# Notice: since there are unkown words in test samples.\n",
    "#  Following ways could handle this (choose one or create your own):\n",
    "#  1). mark all words that appear only once in the data with a \"UNK-x\" tag\n",
    "#  2). tag every out-of-vocabulary word with the majority tag among all training samples.\n",
    "#  3). find more methods in https://github.com/Adamouization/POS-Tagging-and-Unknown-Words\n",
    "\n",
    "\n",
    "def get_mostfreq_tag(sents: list):\n",
    "    word_tag_freq = {}\n",
    "    word_mostfreq_tag = {}\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            if word[\"word\"] not in word_tag_freq:\n",
    "                word_tag_freq[word[\"word\"]] = {}\n",
    "            if word[\"tag\"] not in word_tag_freq[word[\"word\"]]:\n",
    "                word_tag_freq[word[\"word\"]][word[\"tag\"]] = 0\n",
    "            word_tag_freq[word[\"word\"]][word[\"tag\"]] += 1\n",
    "    for word in word_tag_freq:\n",
    "        word_mostfreq_tag[word] = max(word_tag_freq[word], key=word_tag_freq[word].get)\n",
    "    return word_mostfreq_tag\n",
    "\n",
    "\n",
    "def predict_baseline(sents: list, word_mostfreq_tag: dict, num_words: int, major_tag: str):\n",
    "    correct = 0\n",
    "    for sent in sents:\n",
    "        for word in sent:\n",
    "            # 将未知词的tag设为major_tag\n",
    "            if word[\"word\"] not in word_mostfreq_tag:\n",
    "                word_mostfreq_tag[word[\"word\"]] = major_tag\n",
    "            if word[\"tag\"] == word_mostfreq_tag[word[\"word\"]]:\n",
    "                correct += 1\n",
    "    return correct / num_words\n",
    "\n",
    "\n",
    "trword_mostfreq_tag = get_mostfreq_tag(train_sents)\n",
    "train_acc = predict_baseline(train_sents, trword_mostfreq_tag, train_num_words, major_tag)\n",
    "test_acc = predict_baseline(test_sents, trword_mostfreq_tag, test_num_words, major_tag)\n",
    "print(\"Accuracy on train:\", train_acc)\n",
    "print(\"Accuracy on test:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e38802c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train with HMM: 0.9756141962907466\n",
      "Accuracy on test with HMM: 0.9622184527515942\n"
     ]
    }
   ],
   "source": [
    "# Task 3 --- Method 2: Build an HMM tagger ---\n",
    "# 1) You should use nltk.tag.HiddenMarkovModelTagger to build an HMM tagger.\n",
    "#    It has parameters: symbols, states, transitions, outputs, priors, transform (ignore it).\n",
    "#    Specify these parameters properly. For example, you can use MLE to estimate transitions, outputs and priors.\n",
    "#    That is, MLE to estimate matrix A (transition matrix), and matrix B (output probabilites) (See. Page 8.4.3)\n",
    "# 2) After build your model, report both the accuracy of HMM tagger for train samples and test samples.\n",
    "# 3) Compared with your baseline method, discuss that why your HMM tagger is better/worse than baseline method.\n",
    "\n",
    "# Notice: You may also need to handle unknown words just like Task 2.\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import HiddenMarkovModelTagger\n",
    "from nltk.probability import ConditionalFreqDist, ConditionalProbDist, MLEProbDist\n",
    "\n",
    "# fmt:off\n",
    "def build_HMM_tagger(train_sents:list, test_sents:list, major_tag:str):\n",
    "    symbols = set([word[\"word\"] for sent in train_sents for word in sent])\n",
    "    states = set([word[\"tag\"] for sent in train_sents for word in sent])\n",
    "    # 将未知词的tag设为major_tag\n",
    "    for sent in test_sents:\n",
    "        for word in sent:\n",
    "            if word[\"word\"] not in symbols:\n",
    "                symbols.add(word[\"word\"])\n",
    "                train_sents.append([{\"word\": word[\"word\"], \"tag\": major_tag}])\n",
    "    transitions = ConditionalProbDist(\n",
    "        ConditionalFreqDist(\n",
    "            (tag1, tag2) \n",
    "            for sent in train_sents\n",
    "            for (tag1, tag2) in nltk.bigrams([word[\"tag\"] for word in sent])\n",
    "        ),\n",
    "        MLEProbDist,\n",
    "    )\n",
    "    outputs = ConditionalProbDist(\n",
    "        ConditionalFreqDist(\n",
    "            (word[\"tag\"], word[\"word\"])\n",
    "            for sent in train_sents\n",
    "            for word in sent\n",
    "        ),\n",
    "        MLEProbDist,\n",
    "    )\n",
    "    priors = MLEProbDist(\n",
    "        nltk.FreqDist(\n",
    "            sent[0][\"tag\"]\n",
    "            for sent in train_sents if len(sent) > 1\n",
    "        )\n",
    "    )\n",
    "    return nltk.tag.HiddenMarkovModelTagger(\n",
    "        symbols=symbols,\n",
    "        states=states,\n",
    "        transitions=transitions,\n",
    "        outputs=outputs,\n",
    "        priors=priors\n",
    "    )\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "for sent in train_sents:\n",
    "    train_data.append([(word[\"word\"], word[\"tag\"]) for word in sent])\n",
    "for sent in test_sents:\n",
    "    test_data.append([(word[\"word\"], word[\"tag\"]) for word in sent])\n",
    "\n",
    "HMM_tagger = build_HMM_tagger(train_sents[:], test_sents[:], major_tag)\n",
    "train_acc = HMM_tagger.accuracy(train_data)\n",
    "test_acc = HMM_tagger.accuracy(test_data)\n",
    "print(\"Accuracy on train with HMM:\", train_acc)\n",
    "print(\"Accuracy on test with HMM:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c58ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 --- Method 3: Fine-tuning on BERT-base model for POS-tagging ---\n",
    "#\n",
    "# 1) You may download a BERT model (say, you choose BERT-base cased)\n",
    "#    and use tools in https://github.com/huggingface/transformers\n",
    "# 2) After build your model, report both the accuracy of BERT tagger for train samples and test samples.\n",
    "# 3) Compared with Method 1,2, discuss that why your BERT tagger is better/worse than these two.\n",
    "#    1. 上下文理解能力更强： BERT 是基于 Transformer 架构的预训练模型，能够有效地捕捉句子中的上下文信息，从而更好地理解句子中的语义和语境。传统基线模型和 HMM 可能局限于局部特征或固定的上下文窗口，不能很好地捕捉长距离依赖关系\n",
    "#    2. 端到端学习： BERT 是一个端到端的模型，可以直接在标注数据上进行端到端的监督学习，而不需要手工设计特征或规则。相比之下，传统的基线模型和 HMM 需要手动设计特征和转移概率，这通常需要领域知识和经验\n",
    "#    3. 迁移学习： BERT 是在大规模无监督数据上进行预训练的，然后在特定任务上进行微调。这种迁移学习的方式可以使 BERT 在少量标注数据上也能取得很好的性能，而传统的基线模型和 HMM 在数据稀缺的情况下往往表现不佳\n",
    "#    4. 处理非结构化文本能力： BERT 是为处理非结构化文本设计的，可以直接处理原始文本输入，而不需要额外的预处理或特征工程。传统的基线模型和 HMM 可能需要手动设计规则来处理非结构化文本，这增加了系统的复杂性和工程难度\n",
    "#    5. 全局信息捕捉： BERT 是一个深层模型，可以利用多层的注意力机制来捕捉句子中的全局信息。相比之下，传统的基线模型和 HMM 可能只能利用局部信息，无法充分利用全局信息\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "\n",
    "class POSDataset(Dataset):\n",
    "    def __init__(self, sents: list, TAGS: list, tokenizer: BertTokenizer, seq_len:int = 256):\n",
    "        self.src = []\n",
    "        self.tgt = []\n",
    "        self.src_mask = []\n",
    "        pad_token = tokenizer.pad_token_id\n",
    "        for sent in sents:\n",
    "            words = [word[\"word\"] for word in sent]\n",
    "            tags = [word[\"tag\"] for word in sent]\n",
    "            ids = tokenizer(words, is_split_into_words=True, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"].squeeze(0)\n",
    "            tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "            words_stack = list(\"|\".join(words))\n",
    "            words_stack.append(\"|\")\n",
    "\n",
    "            stack_idx = 0\n",
    "            tags_idx = 0\n",
    "            labels = []\n",
    "            for token in tokens:\n",
    "                if token.startswith(\"##\"):\n",
    "                    assert token[2] == words_stack[stack_idx]\n",
    "                    stack_idx += len(token) - 2\n",
    "                    labels.append(\"X\")\n",
    "                else:\n",
    "                    assert token[0] == words_stack[stack_idx]\n",
    "                    stack_idx += len(token)\n",
    "                    labels.append(tags[tags_idx])\n",
    "                if words_stack[stack_idx] == \"|\":\n",
    "                    stack_idx += 1\n",
    "                    tags_idx += 1\n",
    "            \n",
    "            num_pad_tokens = seq_len - len(ids)\n",
    "            ids = torch.cat([ids, torch.tensor([pad_token] * num_pad_tokens)])\n",
    "            labels = labels + [\"X\"] * num_pad_tokens\n",
    "            labels = torch.tensor([TAGS.index(tag) for tag in labels])\n",
    "            assert len(ids) == seq_len, len(ids)\n",
    "            assert len(labels) == seq_len, len(labels)\n",
    "            \n",
    "            self.src.append(ids)\n",
    "            self.tgt.append(labels)\n",
    "            self.src_mask.append(torch.ones_like(ids))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"src\": self.src[idx], \"src_mask\": self.src_mask[idx], \"tgt\": self.tgt[idx]}\n",
    "\n",
    "seq_len = 256\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "train_dataset = POSDataset(train_sents, TAGS, tokenizer, seq_len)\n",
    "test_dataset = POSDataset(test_sents, TAGS, tokenizer, seq_len)\n",
    "train_loader = DataLoader(train_dataset, 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "936fb9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(TAGS)).cuda()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73c60e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, writer:SummaryWriter):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"src\"].cuda()\n",
    "        attention_mask = batch[\"src_mask\"].cuda()\n",
    "        labels = batch[\"tgt\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "        writer.add_scalar(\"Loss\", loss.item(), global_step=writer._n_iter)\n",
    "        writer.flush()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, dataloader, writer):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"src\"].cuda()\n",
    "            attention_mask = batch[\"src_mask\"].cuda()\n",
    "            labels = batch[\"tgt\"].cuda()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            mask = attention_mask.bool()\n",
    "            correct = (predictions == labels) & mask\n",
    "            total_correct += correct.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix(accuracy=total_correct / total_tokens)\n",
    "            writer.add_scalar(\"Accuracy\", total_correct / total_tokens, global_step=writer._n_iter)\n",
    "            \n",
    "\n",
    "    accuracy = total_correct / total_tokens\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e8d9410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613bef78686c4d89b10f165f0519bf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7c70c2cef2494f989f45bdcc62a713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7597dd524344bcb80404798983cf589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train Loss: 0.0191\n",
      "Train Accuracy: 0.9992\n",
      "Test Accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652b100299a84f5aafd4c547449a432f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f7dd016fff43ff8a31816324bbc66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7041e5d616d4fa9a289a802aa1852c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n",
      "Train Loss: 0.0034\n",
      "Train Accuracy: 0.9995\n",
      "Test Accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e823333599e0480e98ba1dfe2fd05152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a248a7efeb1410fb5c00e95f1b43078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eed8acea19241b4bc31505fc5b13729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "Train Loss: 0.0023\n",
      "Train Accuracy: 0.9996\n",
      "Test Accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00a23527e194adfbb2fc0bff3f4f7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d365a265b20b430782bc5445e79044ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611fcde04e4d40fab871150da1e748f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/722 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "Train Loss: 0.0016\n",
      "Train Accuracy: 0.9997\n",
      "Test Accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "writer = SummaryWriter()\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, writer)\n",
    "    train_accuracy = evaluate(model, train_loader, writer)\n",
    "    test_accuracy = evaluate(model, test_loader, writer)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
