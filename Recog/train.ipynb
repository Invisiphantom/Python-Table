{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25cfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from util import ManualMFCC, SpeechDataset, SpeechRecognizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaadf31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = SpeechRecognizer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6150bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 6380 个音频文件\n",
      "处理到  0\n",
      "处理到  100\n",
      "处理到  200\n",
      "处理到  300\n",
      "处理到  400\n",
      "处理到  500\n",
      "处理到  600\n",
      "处理到  700\n",
      "处理到  800\n",
      "处理到  900\n",
      "处理到  1000\n",
      "处理到  1100\n",
      "处理到  1200\n",
      "处理到  1300\n",
      "处理到  1400\n",
      "处理到  1500\n",
      "处理到  1600\n",
      "处理到  1700\n",
      "处理到  1800\n",
      "处理到  1900\n",
      "处理到  2000\n",
      "处理到  2100\n",
      "处理到  2200\n",
      "处理到  2300\n",
      "处理到  2400\n",
      "处理到  2500\n",
      "处理到  2600\n",
      "处理到  2700\n",
      "处理到  2800\n",
      "处理到  2900\n",
      "处理到  3000\n",
      "处理到  3100\n",
      "处理到  3200\n",
      "处理到  3300\n",
      "处理到  3400\n",
      "处理到  3500\n",
      "处理到  3600\n",
      "处理到  3700\n",
      "处理到  3800\n",
      "处理到  3900\n",
      "处理到  4000\n",
      "处理到  4100\n",
      "处理到  4200\n",
      "处理到  4300\n",
      "处理到  4400\n",
      "处理到  4500\n",
      "处理到  4600\n",
      "处理到  4700\n",
      "处理到  4800\n",
      "处理到  4900\n",
      "处理到  5000\n",
      "处理到  5100\n",
      "处理到  5200\n",
      "处理到  5300\n",
      "处理到  5400\n",
      "处理到  5500\n",
      "处理到  5600\n",
      "处理到  5700\n",
      "处理到  5800\n",
      "处理到  5900\n",
      "处理到  6000\n",
      "处理到  6100\n",
      "处理到  6200\n",
      "处理到  6300\n",
      "总样本数(包含增强): 19140\n"
     ]
    }
   ],
   "source": [
    "# 初始化MFCC提取器\n",
    "mfcc_extractor = ManualMFCC(sample_rate=8000)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "VOCAB = {\"00\": \"数字\", \"01\": \"语音\", \"02\": \"语言\", \"03\": \"处理\", \"04\": \"中国\", \"05\": \"忠告\", \"06\": \"北京\", \"07\": \"背景\", \"08\": \"上海\", \"09\": \"商行\", \"10\": \"Speech\", \"11\": \"Speaker\", \"12\": \"Signal\", \"13\": \"Sequence\", \"14\": \"Processing\", \"15\": \"Print\", \"16\": \"Project\", \"17\": \"File\", \"18\": \"Open\", \"19\": \"Close\"}\n",
    "dataset = SpeechDataset(\"\", VOCAB, mfcc_extractor)\n",
    "\n",
    "# 定义划分比例\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# 随机划分\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2bdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for mfcc, labels in dataloader:\n",
    "            mfcc = mfcc.permute(0, 2, 1).to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(mfcc)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(dataloader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72131e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93e1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 2.5930, Train Acc: 13.19%, Val Loss: 2.1914, Val Acc: 20.79%\n",
      "Epoch [2/100], Train Loss: 1.9527, Train Acc: 30.86%, Val Loss: 1.5501, Val Acc: 44.20%\n",
      "Epoch [3/100], Train Loss: 1.4554, Train Acc: 48.11%, Val Loss: 1.3541, Val Acc: 52.19%\n",
      "Epoch [4/100], Train Loss: 1.0187, Train Acc: 64.78%, Val Loss: 0.9114, Val Acc: 68.08%\n",
      "Epoch [5/100], Train Loss: 0.7525, Train Acc: 73.82%, Val Loss: 0.6628, Val Acc: 77.53%\n",
      "Epoch [6/100], Train Loss: 0.7164, Train Acc: 75.30%, Val Loss: 0.5716, Val Acc: 80.28%\n",
      "Epoch [7/100], Train Loss: 0.5243, Train Acc: 82.02%, Val Loss: 0.4680, Val Acc: 84.22%\n",
      "Epoch [8/100], Train Loss: 0.4491, Train Acc: 84.99%, Val Loss: 0.4726, Val Acc: 84.30%\n",
      "Epoch [9/100], Train Loss: 0.3702, Train Acc: 87.88%, Val Loss: 0.3350, Val Acc: 89.29%\n",
      "Epoch [10/100], Train Loss: 0.3105, Train Acc: 89.90%, Val Loss: 0.3642, Val Acc: 88.38%\n",
      "Epoch [11/100], Train Loss: 0.3483, Train Acc: 88.53%, Val Loss: 0.4277, Val Acc: 86.31%\n",
      "Epoch [12/100], Train Loss: 0.2525, Train Acc: 91.93%, Val Loss: 0.2713, Val Acc: 91.38%\n",
      "Epoch [13/100], Train Loss: 0.2162, Train Acc: 92.92%, Val Loss: 0.2335, Val Acc: 92.16%\n",
      "Epoch [14/100], Train Loss: 0.2146, Train Acc: 93.06%, Val Loss: 0.2700, Val Acc: 90.94%\n",
      "Epoch [15/100], Train Loss: 0.1769, Train Acc: 94.39%, Val Loss: 0.1753, Val Acc: 94.67%\n",
      "Epoch [16/100], Train Loss: 0.1533, Train Acc: 94.96%, Val Loss: 0.1673, Val Acc: 94.70%\n",
      "Epoch [17/100], Train Loss: 0.1472, Train Acc: 95.27%, Val Loss: 0.1760, Val Acc: 94.41%\n",
      "Epoch [18/100], Train Loss: 0.1454, Train Acc: 95.35%, Val Loss: 0.1533, Val Acc: 95.14%\n",
      "Epoch [19/100], Train Loss: 0.1569, Train Acc: 94.96%, Val Loss: 0.1527, Val Acc: 95.32%\n",
      "Epoch [20/100], Train Loss: 0.1126, Train Acc: 96.51%, Val Loss: 0.1486, Val Acc: 95.38%\n",
      "Epoch [21/100], Train Loss: 0.1235, Train Acc: 96.08%, Val Loss: 0.1614, Val Acc: 95.38%\n",
      "Epoch [22/100], Train Loss: 0.1000, Train Acc: 96.98%, Val Loss: 0.1612, Val Acc: 95.56%\n",
      "Epoch [23/100], Train Loss: 0.0909, Train Acc: 97.08%, Val Loss: 0.1155, Val Acc: 96.42%\n",
      "Epoch [24/100], Train Loss: 0.0957, Train Acc: 97.00%, Val Loss: 0.1113, Val Acc: 96.42%\n",
      "Epoch [25/100], Train Loss: 0.0951, Train Acc: 97.12%, Val Loss: 0.0983, Val Acc: 97.31%\n",
      "Epoch [26/100], Train Loss: 0.0655, Train Acc: 98.07%, Val Loss: 0.0941, Val Acc: 97.13%\n",
      "Epoch [27/100], Train Loss: 0.0703, Train Acc: 97.87%, Val Loss: 0.1409, Val Acc: 96.06%\n",
      "Epoch [28/100], Train Loss: 0.0725, Train Acc: 97.69%, Val Loss: 0.1014, Val Acc: 96.97%\n",
      "Epoch [29/100], Train Loss: 0.0532, Train Acc: 98.41%, Val Loss: 0.0859, Val Acc: 97.44%\n",
      "Epoch [30/100], Train Loss: 0.0738, Train Acc: 97.79%, Val Loss: 0.1150, Val Acc: 96.63%\n",
      "Epoch [31/100], Train Loss: 0.0412, Train Acc: 98.72%, Val Loss: 0.0811, Val Acc: 97.52%\n",
      "Epoch [32/100], Train Loss: 0.0633, Train Acc: 98.01%, Val Loss: 0.1270, Val Acc: 95.85%\n",
      "Epoch [33/100], Train Loss: 0.0649, Train Acc: 98.07%, Val Loss: 0.0996, Val Acc: 96.68%\n",
      "Epoch [34/100], Train Loss: 0.0523, Train Acc: 98.43%, Val Loss: 0.1213, Val Acc: 96.68%\n",
      "Epoch [35/100], Train Loss: 0.0425, Train Acc: 98.69%, Val Loss: 0.0971, Val Acc: 97.10%\n",
      "Epoch [36/100], Train Loss: 0.0367, Train Acc: 98.87%, Val Loss: 0.0739, Val Acc: 97.86%\n",
      "Epoch [37/100], Train Loss: 0.0527, Train Acc: 98.41%, Val Loss: 0.1143, Val Acc: 96.89%\n",
      "Epoch [38/100], Train Loss: 0.0425, Train Acc: 98.65%, Val Loss: 0.0845, Val Acc: 97.52%\n",
      "Epoch [39/100], Train Loss: 0.0422, Train Acc: 98.75%, Val Loss: 0.0663, Val Acc: 97.86%\n",
      "Epoch [40/100], Train Loss: 0.0242, Train Acc: 99.17%, Val Loss: 0.0826, Val Acc: 97.62%\n",
      "Epoch [41/100], Train Loss: 0.0227, Train Acc: 99.29%, Val Loss: 0.0691, Val Acc: 97.99%\n",
      "Epoch [42/100], Train Loss: 0.0303, Train Acc: 99.12%, Val Loss: 0.0824, Val Acc: 97.91%\n",
      "Epoch [43/100], Train Loss: 0.0352, Train Acc: 98.88%, Val Loss: 0.0587, Val Acc: 98.30%\n",
      "Epoch [44/100], Train Loss: 0.0190, Train Acc: 99.40%, Val Loss: 0.0637, Val Acc: 98.35%\n",
      "Epoch [45/100], Train Loss: 0.0125, Train Acc: 99.68%, Val Loss: 0.0758, Val Acc: 98.01%\n",
      "Epoch [46/100], Train Loss: 0.0242, Train Acc: 99.31%, Val Loss: 0.0545, Val Acc: 98.43%\n",
      "Epoch [47/100], Train Loss: 0.0256, Train Acc: 99.26%, Val Loss: 0.0678, Val Acc: 97.96%\n",
      "Epoch [48/100], Train Loss: 0.0281, Train Acc: 99.19%, Val Loss: 0.0534, Val Acc: 98.56%\n",
      "Epoch [49/100], Train Loss: 0.0174, Train Acc: 99.49%, Val Loss: 0.0601, Val Acc: 98.22%\n",
      "Epoch [50/100], Train Loss: 0.0105, Train Acc: 99.67%, Val Loss: 0.0473, Val Acc: 98.59%\n",
      "Epoch [51/100], Train Loss: 0.0100, Train Acc: 99.73%, Val Loss: 0.0590, Val Acc: 98.43%\n",
      "Epoch [52/100], Train Loss: 0.0239, Train Acc: 99.29%, Val Loss: 0.0688, Val Acc: 98.38%\n",
      "Epoch [53/100], Train Loss: 0.0117, Train Acc: 99.69%, Val Loss: 0.0630, Val Acc: 97.99%\n",
      "Epoch [54/100], Train Loss: 0.0173, Train Acc: 99.58%, Val Loss: 0.0732, Val Acc: 98.09%\n",
      "Epoch [55/100], Train Loss: 0.0103, Train Acc: 99.66%, Val Loss: 0.0628, Val Acc: 98.56%\n",
      "Epoch [56/100], Train Loss: 0.0084, Train Acc: 99.75%, Val Loss: 0.0633, Val Acc: 98.48%\n",
      "Epoch [57/100], Train Loss: 0.0145, Train Acc: 99.59%, Val Loss: 0.0675, Val Acc: 98.46%\n",
      "Epoch [58/100], Train Loss: 0.0145, Train Acc: 99.59%, Val Loss: 0.0632, Val Acc: 98.46%\n",
      "Epoch [59/100], Train Loss: 0.0070, Train Acc: 99.82%, Val Loss: 0.0565, Val Acc: 98.43%\n",
      "Epoch [60/100], Train Loss: 0.0094, Train Acc: 99.75%, Val Loss: 0.0565, Val Acc: 98.54%\n",
      "Epoch [61/100], Train Loss: 0.0041, Train Acc: 99.90%, Val Loss: 0.0526, Val Acc: 98.56%\n",
      "Epoch [62/100], Train Loss: 0.0069, Train Acc: 99.81%, Val Loss: 0.0493, Val Acc: 98.75%\n",
      "Epoch [63/100], Train Loss: 0.0057, Train Acc: 99.87%, Val Loss: 0.0565, Val Acc: 98.62%\n",
      "Epoch [64/100], Train Loss: 0.0084, Train Acc: 99.80%, Val Loss: 0.0511, Val Acc: 98.67%\n",
      "Epoch [65/100], Train Loss: 0.0050, Train Acc: 99.83%, Val Loss: 0.0579, Val Acc: 98.43%\n",
      "Epoch [66/100], Train Loss: 0.0062, Train Acc: 99.84%, Val Loss: 0.0467, Val Acc: 98.69%\n",
      "Epoch [67/100], Train Loss: 0.0020, Train Acc: 99.93%, Val Loss: 0.0389, Val Acc: 98.82%\n",
      "Epoch [68/100], Train Loss: 0.0010, Train Acc: 99.98%, Val Loss: 0.0373, Val Acc: 98.93%\n",
      "Epoch [69/100], Train Loss: 0.0011, Train Acc: 99.99%, Val Loss: 0.0432, Val Acc: 99.01%\n",
      "Epoch [70/100], Train Loss: 0.0016, Train Acc: 99.97%, Val Loss: 0.0439, Val Acc: 98.93%\n",
      "Epoch [71/100], Train Loss: 0.0006, Train Acc: 99.99%, Val Loss: 0.0441, Val Acc: 99.09%\n",
      "Epoch [72/100], Train Loss: 0.0009, Train Acc: 99.97%, Val Loss: 0.0509, Val Acc: 98.80%\n",
      "Epoch [73/100], Train Loss: 0.0047, Train Acc: 99.91%, Val Loss: 0.0410, Val Acc: 98.98%\n",
      "Epoch [74/100], Train Loss: 0.0017, Train Acc: 99.95%, Val Loss: 0.0467, Val Acc: 98.96%\n",
      "Epoch [75/100], Train Loss: 0.0016, Train Acc: 99.96%, Val Loss: 0.0509, Val Acc: 98.90%\n",
      "Epoch [76/100], Train Loss: 0.0007, Train Acc: 99.98%, Val Loss: 0.0466, Val Acc: 98.93%\n",
      "Epoch [77/100], Train Loss: 0.0005, Train Acc: 99.99%, Val Loss: 0.0428, Val Acc: 98.96%\n",
      "Epoch [78/100], Train Loss: 0.0004, Train Acc: 99.99%, Val Loss: 0.0433, Val Acc: 98.96%\n",
      "Epoch [79/100], Train Loss: 0.0004, Train Acc: 99.99%, Val Loss: 0.0454, Val Acc: 98.98%\n",
      "Epoch [80/100], Train Loss: 0.0004, Train Acc: 99.99%, Val Loss: 0.0443, Val Acc: 99.03%\n",
      "Epoch [81/100], Train Loss: 0.0003, Train Acc: 99.99%, Val Loss: 0.0474, Val Acc: 99.01%\n",
      "Epoch [82/100], Train Loss: 0.0004, Train Acc: 99.99%, Val Loss: 0.0478, Val Acc: 99.03%\n",
      "Epoch [83/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0509, Val Acc: 98.88%\n",
      "Epoch [84/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0495, Val Acc: 98.96%\n",
      "Epoch [85/100], Train Loss: 0.0003, Train Acc: 99.99%, Val Loss: 0.0483, Val Acc: 98.96%\n",
      "Epoch [86/100], Train Loss: 0.0003, Train Acc: 99.99%, Val Loss: 0.0459, Val Acc: 98.96%\n",
      "Epoch [87/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0464, Val Acc: 98.98%\n",
      "Epoch [88/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0471, Val Acc: 99.03%\n",
      "Epoch [89/100], Train Loss: 0.0001, Train Acc: 99.99%, Val Loss: 0.0493, Val Acc: 98.98%\n",
      "Epoch [90/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0510, Val Acc: 98.98%\n",
      "Epoch [91/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0519, Val Acc: 99.01%\n",
      "Epoch [92/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0518, Val Acc: 99.03%\n",
      "Epoch [93/100], Train Loss: 0.0001, Train Acc: 99.99%, Val Loss: 0.0505, Val Acc: 99.03%\n",
      "Epoch [94/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0496, Val Acc: 99.03%\n",
      "Epoch [95/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0501, Val Acc: 98.93%\n",
      "Epoch [96/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0511, Val Acc: 98.98%\n",
      "Epoch [97/100], Train Loss: 0.0002, Train Acc: 99.99%, Val Loss: 0.0510, Val Acc: 98.93%\n",
      "Epoch [98/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0518, Val Acc: 98.93%\n",
      "Epoch [99/100], Train Loss: 0.0001, Train Acc: 99.99%, Val Loss: 0.0516, Val Acc: 98.96%\n",
      "Epoch [100/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.0520, Val Acc: 98.98%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    for batch_idx, (mfcc, labels) in enumerate(train_loader):\n",
    "        mfcc = mfcc.permute(0, 2, 1).to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 打印日志\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"归一化混淆矩阵\")\n",
    "    else:\n",
    "        print('未归一化混淆矩阵')\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd',\n",
    "                cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10179fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(val_labels, val_preds, classes=class_names, \n",
    "                             title=f\"最佳模型混淆矩阵 (Epoch {epoch+1})\")\n",
    "plot_confusion_matrix(val_labels, val_preds, classes=class_names, \n",
    "                        normalize=True, title=f\"归一化混淆矩阵 (Epoch {epoch+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
