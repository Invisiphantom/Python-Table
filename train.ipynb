{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25cfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from util import ManualMFCC, SpeechDataset, SpeechRecognizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaadf31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = SpeechRecognizer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6150bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 2400 个音频文件\n"
     ]
    }
   ],
   "source": [
    "# 初始化MFCC提取器\n",
    "mfcc_extractor = ManualMFCC(sample_rate=8000)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "VOCAB = {\"00\": \"数字\", \"01\": \"语音\", \"02\": \"语言\", \"03\": \"处理\", \"04\": \"中国\", \"05\": \"忠告\", \"06\": \"北京\", \"07\": \"背景\", \"08\": \"上海\", \"09\": \"商行\", \"10\": \"Speech\", \"11\": \"Speaker\", \"12\": \"Signal\", \"13\": \"Sequence\", \"14\": \"Processing\", \"15\": \"Print\", \"16\": \"Project\", \"17\": \"File\", \"18\": \"Open\", \"19\": \"Close\"}\n",
    "dataset = SpeechDataset(\"\", VOCAB, mfcc_extractor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93e1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 285.49, Accuracy: 8.292%\n",
      "Epoch [2/200], Loss: 229.36, Accuracy: 23.792%\n",
      "Epoch [3/200], Loss: 189.81, Accuracy: 32.917%\n",
      "Epoch [4/200], Loss: 164.47, Accuracy: 40.208%\n",
      "Epoch [5/200], Loss: 144.81, Accuracy: 46.500%\n",
      "Epoch [6/200], Loss: 128.61, Accuracy: 52.792%\n",
      "Epoch [7/200], Loss: 106.24, Accuracy: 61.625%\n",
      "Epoch [8/200], Loss: 86.56, Accuracy: 67.667%\n",
      "Epoch [9/200], Loss: 71.65, Accuracy: 75.375%\n",
      "Epoch [10/200], Loss: 61.32, Accuracy: 78.500%\n",
      "Epoch [11/200], Loss: 58.92, Accuracy: 79.667%\n",
      "Epoch [12/200], Loss: 50.94, Accuracy: 82.125%\n",
      "Epoch [13/200], Loss: 42.96, Accuracy: 84.375%\n",
      "Epoch [14/200], Loss: 38.13, Accuracy: 87.333%\n",
      "Epoch [15/200], Loss: 40.15, Accuracy: 86.500%\n",
      "Epoch [16/200], Loss: 35.70, Accuracy: 87.750%\n",
      "Epoch [17/200], Loss: 27.08, Accuracy: 91.208%\n",
      "Epoch [18/200], Loss: 23.52, Accuracy: 91.833%\n",
      "Epoch [19/200], Loss: 22.68, Accuracy: 92.208%\n",
      "Epoch [20/200], Loss: 19.93, Accuracy: 93.250%\n",
      "Epoch [21/200], Loss: 22.54, Accuracy: 92.708%\n",
      "Epoch [22/200], Loss: 19.83, Accuracy: 92.917%\n",
      "Epoch [23/200], Loss: 17.18, Accuracy: 94.583%\n",
      "Epoch [24/200], Loss: 17.82, Accuracy: 94.542%\n",
      "Epoch [25/200], Loss: 18.89, Accuracy: 93.583%\n",
      "Epoch [26/200], Loss: 18.29, Accuracy: 94.417%\n",
      "Epoch [27/200], Loss: 14.12, Accuracy: 95.292%\n",
      "Epoch [28/200], Loss: 15.88, Accuracy: 95.083%\n",
      "Epoch [29/200], Loss: 12.82, Accuracy: 96.000%\n",
      "Epoch [30/200], Loss: 12.39, Accuracy: 96.167%\n",
      "Epoch [31/200], Loss: 7.82, Accuracy: 97.792%\n",
      "Epoch [32/200], Loss: 12.47, Accuracy: 95.917%\n",
      "Epoch [33/200], Loss: 10.26, Accuracy: 96.667%\n",
      "Epoch [34/200], Loss: 12.25, Accuracy: 96.000%\n",
      "Epoch [35/200], Loss: 10.63, Accuracy: 96.625%\n",
      "Epoch [36/200], Loss: 16.11, Accuracy: 95.333%\n",
      "Epoch [37/200], Loss: 5.37, Accuracy: 98.625%\n",
      "Epoch [38/200], Loss: 4.12, Accuracy: 99.125%\n",
      "Epoch [39/200], Loss: 4.19, Accuracy: 98.792%\n",
      "Epoch [40/200], Loss: 3.88, Accuracy: 98.833%\n",
      "Epoch [41/200], Loss: 3.88, Accuracy: 98.917%\n",
      "Epoch [42/200], Loss: 3.74, Accuracy: 99.250%\n",
      "Epoch [43/200], Loss: 3.01, Accuracy: 99.125%\n",
      "Epoch [44/200], Loss: 4.88, Accuracy: 98.458%\n",
      "Epoch [45/200], Loss: 10.61, Accuracy: 96.417%\n",
      "Epoch [46/200], Loss: 4.83, Accuracy: 98.667%\n",
      "Epoch [47/200], Loss: 3.93, Accuracy: 98.958%\n",
      "Epoch [48/200], Loss: 7.67, Accuracy: 97.458%\n",
      "Epoch [49/200], Loss: 4.79, Accuracy: 98.750%\n",
      "Epoch [50/200], Loss: 4.76, Accuracy: 98.750%\n",
      "Epoch [51/200], Loss: 3.09, Accuracy: 99.083%\n",
      "Epoch [52/200], Loss: 4.40, Accuracy: 98.583%\n",
      "Epoch [53/200], Loss: 5.24, Accuracy: 98.375%\n",
      "Epoch [54/200], Loss: 4.46, Accuracy: 98.375%\n",
      "Epoch [55/200], Loss: 2.93, Accuracy: 99.375%\n",
      "Epoch [56/200], Loss: 1.69, Accuracy: 99.542%\n",
      "Epoch [57/200], Loss: 4.53, Accuracy: 98.667%\n",
      "Epoch [58/200], Loss: 6.22, Accuracy: 98.333%\n",
      "Epoch [59/200], Loss: 5.44, Accuracy: 98.000%\n",
      "Epoch [60/200], Loss: 6.83, Accuracy: 98.083%\n",
      "Epoch [61/200], Loss: 4.35, Accuracy: 98.583%\n",
      "Epoch [62/200], Loss: 4.18, Accuracy: 98.792%\n",
      "Epoch [63/200], Loss: 4.68, Accuracy: 98.500%\n",
      "Epoch [64/200], Loss: 2.53, Accuracy: 99.125%\n",
      "Epoch [65/200], Loss: 1.23, Accuracy: 99.792%\n",
      "Epoch [66/200], Loss: 0.57, Accuracy: 99.917%\n",
      "Epoch [67/200], Loss: 0.46, Accuracy: 99.917%\n",
      "Epoch [68/200], Loss: 0.47, Accuracy: 99.875%\n",
      "Epoch [69/200], Loss: 0.42, Accuracy: 99.875%\n",
      "Epoch [70/200], Loss: 0.34, Accuracy: 99.917%\n",
      "Epoch [71/200], Loss: 0.40, Accuracy: 99.875%\n",
      "Epoch [72/200], Loss: 0.39, Accuracy: 99.875%\n",
      "Epoch [73/200], Loss: 0.34, Accuracy: 99.917%\n",
      "Epoch [74/200], Loss: 0.36, Accuracy: 99.833%\n",
      "Epoch [75/200], Loss: 0.25, Accuracy: 99.917%\n",
      "Epoch [76/200], Loss: 0.31, Accuracy: 99.875%\n",
      "Epoch [77/200], Loss: 0.24, Accuracy: 99.958%\n",
      "Epoch [78/200], Loss: 0.50, Accuracy: 99.792%\n",
      "Epoch [79/200], Loss: 3.55, Accuracy: 98.833%\n",
      "Epoch [80/200], Loss: 14.06, Accuracy: 95.250%\n",
      "Epoch [81/200], Loss: 10.30, Accuracy: 96.833%\n",
      "Epoch [82/200], Loss: 8.25, Accuracy: 97.625%\n",
      "Epoch [83/200], Loss: 4.92, Accuracy: 98.167%\n",
      "Epoch [84/200], Loss: 3.59, Accuracy: 99.125%\n",
      "Epoch [85/200], Loss: 2.06, Accuracy: 99.375%\n",
      "Epoch [86/200], Loss: 0.97, Accuracy: 99.792%\n",
      "Epoch [87/200], Loss: 0.72, Accuracy: 99.875%\n",
      "Epoch [88/200], Loss: 0.58, Accuracy: 99.875%\n",
      "Epoch [89/200], Loss: 0.51, Accuracy: 99.917%\n",
      "Epoch [90/200], Loss: 0.40, Accuracy: 99.875%\n",
      "Epoch [91/200], Loss: 0.45, Accuracy: 99.917%\n",
      "Epoch [92/200], Loss: 0.41, Accuracy: 99.917%\n",
      "Epoch [93/200], Loss: 0.33, Accuracy: 99.833%\n",
      "Epoch [94/200], Loss: 0.34, Accuracy: 99.875%\n",
      "Epoch [95/200], Loss: 0.34, Accuracy: 99.917%\n",
      "Epoch [96/200], Loss: 0.25, Accuracy: 99.917%\n",
      "Epoch [97/200], Loss: 0.36, Accuracy: 99.917%\n",
      "Epoch [98/200], Loss: 0.26, Accuracy: 99.917%\n",
      "Epoch [99/200], Loss: 0.24, Accuracy: 99.917%\n",
      "Epoch [100/200], Loss: 0.30, Accuracy: 99.792%\n",
      "Epoch [101/200], Loss: 0.23, Accuracy: 99.917%\n",
      "Epoch [102/200], Loss: 0.36, Accuracy: 99.875%\n",
      "Epoch [103/200], Loss: 0.27, Accuracy: 99.917%\n",
      "Epoch [104/200], Loss: 0.23, Accuracy: 99.917%\n",
      "Epoch [105/200], Loss: 0.22, Accuracy: 99.917%\n",
      "Epoch [106/200], Loss: 0.28, Accuracy: 99.875%\n",
      "Epoch [107/200], Loss: 0.29, Accuracy: 99.875%\n",
      "Epoch [108/200], Loss: 0.28, Accuracy: 99.875%\n",
      "Epoch [109/200], Loss: 0.23, Accuracy: 99.917%\n",
      "Epoch [110/200], Loss: 0.21, Accuracy: 99.917%\n",
      "Epoch [111/200], Loss: 0.27, Accuracy: 99.833%\n",
      "Epoch [112/200], Loss: 0.21, Accuracy: 99.875%\n",
      "Epoch [113/200], Loss: 0.27, Accuracy: 99.833%\n",
      "Epoch [114/200], Loss: 0.18, Accuracy: 99.958%\n",
      "Epoch [115/200], Loss: 2.30, Accuracy: 99.375%\n",
      "Epoch [116/200], Loss: 8.28, Accuracy: 97.625%\n",
      "Epoch [117/200], Loss: 3.97, Accuracy: 98.750%\n",
      "Epoch [118/200], Loss: 1.36, Accuracy: 99.625%\n",
      "Epoch [119/200], Loss: 0.59, Accuracy: 99.750%\n",
      "Epoch [120/200], Loss: 0.47, Accuracy: 99.833%\n",
      "Epoch [121/200], Loss: 0.33, Accuracy: 99.958%\n",
      "Epoch [122/200], Loss: 0.38, Accuracy: 99.833%\n",
      "Epoch [123/200], Loss: 0.34, Accuracy: 99.917%\n",
      "Epoch [124/200], Loss: 0.26, Accuracy: 99.917%\n",
      "Epoch [125/200], Loss: 0.39, Accuracy: 99.833%\n",
      "Epoch [126/200], Loss: 0.30, Accuracy: 99.917%\n",
      "Epoch [127/200], Loss: 0.29, Accuracy: 99.875%\n",
      "Epoch [128/200], Loss: 0.21, Accuracy: 99.958%\n",
      "Epoch [129/200], Loss: 0.25, Accuracy: 99.875%\n",
      "Epoch [130/200], Loss: 0.18, Accuracy: 99.917%\n",
      "Epoch [131/200], Loss: 0.18, Accuracy: 99.958%\n",
      "Epoch [132/200], Loss: 0.25, Accuracy: 99.917%\n",
      "Epoch [133/200], Loss: 0.29, Accuracy: 99.917%\n",
      "Epoch [134/200], Loss: 0.29, Accuracy: 99.917%\n",
      "Epoch [135/200], Loss: 0.27, Accuracy: 99.833%\n",
      "Epoch [136/200], Loss: 0.20, Accuracy: 99.917%\n",
      "Epoch [137/200], Loss: 0.29, Accuracy: 99.875%\n",
      "Epoch [138/200], Loss: 0.36, Accuracy: 99.833%\n",
      "Epoch [139/200], Loss: 0.20, Accuracy: 99.917%\n",
      "Epoch [140/200], Loss: 0.14, Accuracy: 99.958%\n",
      "Epoch [141/200], Loss: 0.22, Accuracy: 99.917%\n",
      "Epoch [142/200], Loss: 0.15, Accuracy: 99.958%\n",
      "Epoch [143/200], Loss: 0.25, Accuracy: 99.833%\n",
      "Epoch [144/200], Loss: 0.15, Accuracy: 99.917%\n",
      "Epoch [145/200], Loss: 0.16, Accuracy: 99.958%\n",
      "Epoch [146/200], Loss: 0.15, Accuracy: 99.958%\n",
      "Epoch [147/200], Loss: 0.24, Accuracy: 99.917%\n",
      "Epoch [148/200], Loss: 0.16, Accuracy: 99.917%\n",
      "Epoch [149/200], Loss: 0.12, Accuracy: 100.000%\n",
      "Epoch [150/200], Loss: 0.20, Accuracy: 99.917%\n",
      "Epoch [151/200], Loss: 0.15, Accuracy: 99.917%\n",
      "Epoch [152/200], Loss: 0.22, Accuracy: 99.875%\n",
      "Epoch [153/200], Loss: 0.18, Accuracy: 99.875%\n",
      "Epoch [154/200], Loss: 0.20, Accuracy: 99.875%\n",
      "Epoch [155/200], Loss: 0.18, Accuracy: 99.875%\n",
      "Epoch [156/200], Loss: 0.19, Accuracy: 99.875%\n",
      "Epoch [157/200], Loss: 0.11, Accuracy: 100.000%\n",
      "Epoch [158/200], Loss: 0.13, Accuracy: 99.958%\n",
      "Epoch [159/200], Loss: 0.18, Accuracy: 99.917%\n",
      "Epoch [160/200], Loss: 0.20, Accuracy: 99.875%\n",
      "Epoch [161/200], Loss: 0.22, Accuracy: 99.917%\n",
      "Epoch [162/200], Loss: 0.12, Accuracy: 100.000%\n",
      "Epoch [163/200], Loss: 0.19, Accuracy: 99.875%\n",
      "Epoch [164/200], Loss: 0.16, Accuracy: 99.958%\n",
      "Epoch [165/200], Loss: 0.13, Accuracy: 99.958%\n",
      "Epoch [166/200], Loss: 0.14, Accuracy: 99.875%\n",
      "Epoch [167/200], Loss: 0.24, Accuracy: 99.833%\n",
      "Epoch [168/200], Loss: 0.17, Accuracy: 99.875%\n",
      "Epoch [169/200], Loss: 0.16, Accuracy: 99.875%\n",
      "Epoch [170/200], Loss: 0.20, Accuracy: 99.917%\n",
      "Epoch [171/200], Loss: 0.17, Accuracy: 99.875%\n",
      "Epoch [172/200], Loss: 0.16, Accuracy: 99.917%\n",
      "Epoch [173/200], Loss: 0.20, Accuracy: 99.833%\n",
      "Epoch [174/200], Loss: 0.13, Accuracy: 99.958%\n",
      "Epoch [175/200], Loss: 0.19, Accuracy: 99.833%\n",
      "Epoch [176/200], Loss: 0.20, Accuracy: 99.875%\n",
      "Epoch [177/200], Loss: 0.16, Accuracy: 99.833%\n",
      "Epoch [178/200], Loss: 0.10, Accuracy: 100.000%\n",
      "Epoch [179/200], Loss: 0.14, Accuracy: 99.917%\n",
      "Epoch [180/200], Loss: 0.17, Accuracy: 99.875%\n",
      "Epoch [181/200], Loss: 0.17, Accuracy: 99.875%\n",
      "Epoch [182/200], Loss: 0.19, Accuracy: 99.875%\n",
      "Epoch [183/200], Loss: 0.14, Accuracy: 99.917%\n",
      "Epoch [184/200], Loss: 0.17, Accuracy: 99.875%\n",
      "Epoch [185/200], Loss: 0.19, Accuracy: 99.875%\n",
      "Epoch [186/200], Loss: 0.13, Accuracy: 99.917%\n",
      "Epoch [187/200], Loss: 0.17, Accuracy: 99.958%\n",
      "Epoch [188/200], Loss: 0.14, Accuracy: 99.917%\n",
      "Epoch [189/200], Loss: 0.11, Accuracy: 99.917%\n",
      "Epoch [190/200], Loss: 0.15, Accuracy: 99.875%\n",
      "Epoch [191/200], Loss: 0.13, Accuracy: 99.917%\n",
      "Epoch [192/200], Loss: 0.13, Accuracy: 99.917%\n",
      "Epoch [193/200], Loss: 0.13, Accuracy: 99.917%\n",
      "Epoch [194/200], Loss: 0.16, Accuracy: 99.875%\n",
      "Epoch [195/200], Loss: 0.11, Accuracy: 99.958%\n",
      "Epoch [196/200], Loss: 0.14, Accuracy: 99.917%\n",
      "Epoch [197/200], Loss: 0.13, Accuracy: 99.958%\n",
      "Epoch [198/200], Loss: 0.15, Accuracy: 99.917%\n",
      "Epoch [199/200], Loss: 0.12, Accuracy: 99.958%\n",
      "Epoch [200/200], Loss: 0.13, Accuracy: 99.917%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch_idx, (mfcc, labels) in enumerate(dataloader):\n",
    "        mfcc = mfcc.permute(0, 2, 1).to(device)  # (batch, time, features)\n",
    "        labels = labels.squeeze().to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss*100:.2f}, Accuracy: {epoch_acc:.3f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2341f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10179fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
