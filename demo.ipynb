{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25cfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b1e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualMFCC:\n",
    "    def __init__(self, sample_rate=8000, n_mfcc=13, n_fft=400, hop_length=160, n_mels=40):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        \n",
    "        # 预计算Mel滤波器组\n",
    "        self.mel_filters = self._create_mel_filterbank()\n",
    "        \n",
    "        # 预计算DCT矩阵\n",
    "        self.dct_matrix = self._create_dct_matrix()\n",
    "    \n",
    "    def _hz_to_mel(self, hz):\n",
    "        \"\"\"将频率从Hz转换为Mel刻度\"\"\"\n",
    "        return 2595 * np.log10(1 + hz / 700.0)\n",
    "    \n",
    "    def _mel_to_hz(self, mel):\n",
    "        \"\"\"将频率从Mel刻度转换为Hz\"\"\"\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "    \n",
    "    def _create_mel_filterbank(self):\n",
    "        \"\"\"创建Mel滤波器组\"\"\"\n",
    "        # 计算频率范围\n",
    "        low_freq = 0\n",
    "        high_freq = self.sample_rate / 2\n",
    "        low_mel = self._hz_to_mel(low_freq)\n",
    "        high_mel = self._hz_to_mel(high_freq)\n",
    "        \n",
    "        # 在Mel刻度上均匀分布点\n",
    "        mel_points = np.linspace(low_mel, high_mel, self.n_mels + 2)\n",
    "        hz_points = self._mel_to_hz(mel_points)\n",
    "        \n",
    "        # 转换为FFT bin索引\n",
    "        fft_bins = np.floor((self.n_fft + 1) * hz_points / self.sample_rate).astype(int)\n",
    "        \n",
    "        # 创建滤波器组\n",
    "        filters = np.zeros((self.n_mels, self.n_fft // 2 + 1))\n",
    "        \n",
    "        for i in range(1, self.n_mels + 1):\n",
    "            left = fft_bins[i - 1]\n",
    "            center = fft_bins[i]\n",
    "            right = fft_bins[i + 1]\n",
    "            \n",
    "            # 上升斜坡\n",
    "            if left != center:\n",
    "                filters[i - 1, left:center] = np.linspace(0, 1, center - left)\n",
    "            \n",
    "            # 下降斜坡\n",
    "            if center != right:\n",
    "                filters[i - 1, center:right] = np.linspace(1, 0, right - center)\n",
    "        \n",
    "        return filters\n",
    "    \n",
    "    def _create_dct_matrix(self):\n",
    "        \"\"\"创建DCT(离散余弦变换)矩阵\"\"\"\n",
    "        dct_matrix = np.zeros((self.n_mfcc, self.n_mels))\n",
    "        \n",
    "        for i in range(self.n_mfcc):\n",
    "            for j in range(self.n_mels):\n",
    "                dct_matrix[i, j] = np.cos((np.pi * i / self.n_mels) * (j + 0.5))\n",
    "        \n",
    "        # 归一化\n",
    "        dct_matrix[0, :] *= 1.0 / np.sqrt(self.n_mels)\n",
    "        dct_matrix[1:, :] *= np.sqrt(2.0 / self.n_mels)\n",
    "        \n",
    "        return dct_matrix\n",
    "    \n",
    "    def _compute_power_spectrum(self, frame):\n",
    "        \"\"\"计算单帧的功率谱\"\"\"\n",
    "        # 应用汉宁窗\n",
    "        window = get_window('hann', self.n_fft)\n",
    "        windowed_frame = frame * window\n",
    "        \n",
    "        # 计算FFT\n",
    "        fft_result = fft.fft(windowed_frame, n=self.n_fft)\n",
    "        \n",
    "        # 取前n_fft/2+1个点(对称性)\n",
    "        magnitude = np.abs(fft_result[:self.n_fft // 2 + 1])\n",
    "        \n",
    "        # 计算功率谱\n",
    "        power_spectrum = (1.0 / self.n_fft) * (magnitude ** 2)\n",
    "        \n",
    "        return power_spectrum\n",
    "    \n",
    "    def _compute_mel_spectrum(self, power_spectrum):\n",
    "        \"\"\"计算Mel频谱\"\"\"\n",
    "        # 应用Mel滤波器组\n",
    "        mel_spectrum = np.dot(self.mel_filters, power_spectrum)\n",
    "        \n",
    "        # 转换为dB单位\n",
    "        mel_spectrum = 10 * np.log10(np.maximum(mel_spectrum, 1e-10))\n",
    "        \n",
    "        return mel_spectrum\n",
    "    \n",
    "    def _compute_mfcc(self, mel_spectrum):\n",
    "        \"\"\"计算MFCC系数\"\"\"\n",
    "        # 应用DCT\n",
    "        mfcc = np.dot(self.dct_matrix, mel_spectrum)\n",
    "        \n",
    "        return mfcc\n",
    "    \n",
    "    def load_dat_file(self, filepath):\n",
    "        \"\"\"加载.dat音频文件\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            # 假设.dat文件是16位PCM格式\n",
    "            data = f.read()\n",
    "            # 将字节数据转换为numpy数组\n",
    "            samples = np.array(struct.unpack('<' + 'h'*(len(data)//2), data))\n",
    "            return samples.astype(np.float32) / 32768.0  # 归一化到[-1, 1]\n",
    "    \n",
    "    def compute_mfcc(self, signal, max_length=100):\n",
    "        \"\"\"计算整个信号的MFCC特征\"\"\"\n",
    "        # 确保信号是1D numpy数组\n",
    "        if isinstance(signal, str):\n",
    "            signal = self.load_dat_file(signal)\n",
    "        elif isinstance(signal, list):\n",
    "            signal = np.array(signal)\n",
    "        \n",
    "        # 分帧处理\n",
    "        num_frames = 1 + (len(signal) - self.n_fft) // self.hop_length\n",
    "        mfcc_features = []\n",
    "        \n",
    "        for i in range(num_frames):\n",
    "            start = i * self.hop_length\n",
    "            end = start + self.n_fft\n",
    "            \n",
    "            if end > len(signal):\n",
    "                frame = np.pad(signal[start:], (0, end - len(signal)))\n",
    "            else:\n",
    "                frame = signal[start:end]\n",
    "            \n",
    "            # 计算功率谱\n",
    "            power_spectrum = self._compute_power_spectrum(frame)\n",
    "            \n",
    "            # 计算Mel频谱\n",
    "            mel_spectrum = self._compute_mel_spectrum(power_spectrum)\n",
    "            \n",
    "            # 计算MFCC\n",
    "            mfcc = self._compute_mfcc(mel_spectrum)\n",
    "            \n",
    "            mfcc_features.append(mfcc)\n",
    "        \n",
    "        # 转换为(n_mfcc, time)格式\n",
    "        mfcc_features = np.array(mfcc_features).T\n",
    "        \n",
    "        # 特征长度标准化\n",
    "        if mfcc_features.shape[1] > max_length:\n",
    "            mfcc_features = mfcc_features[:, :max_length]\n",
    "        else:\n",
    "            pad_size = max_length - mfcc_features.shape[1]\n",
    "            mfcc_features = np.pad(mfcc_features, ((0, 0), (0, pad_size)), mode='constant')\n",
    "        \n",
    "        return mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5819d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, root_dir, vocab, mfcc_extractor, max_length=100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): 数据根目录\n",
    "            vocab (dict): 词汇表 {序号: 单词}\n",
    "            mfcc_extractor (ManualMFCC): MFCC提取器\n",
    "            max_length (int): 最大MFCC序列长度\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.vocab = vocab\n",
    "        self.mfcc_extractor: ManualMFCC = mfcc_extractor\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 在初始化时预处理所有数据\n",
    "        self.data = self._preprocess_all_data()\n",
    "\n",
    "    def _build_file_list(self):\n",
    "        \"\"\"构建文件列表和对应的标签\"\"\"\n",
    "        files = []\n",
    "        for word_idx in self.vocab.keys():\n",
    "            for repeat in range(1, 21):\n",
    "                filename = f\"21300240018/{word_idx}/21300240018_{word_idx}_{repeat:02d}.dat\"\n",
    "                files.append((filename, int(word_idx)))\n",
    "        return files\n",
    "\n",
    "    def _preprocess_all_data(self):\n",
    "        \"\"\"预处理所有数据并存储在内存中\"\"\"\n",
    "        file_list = self._build_file_list()\n",
    "        data = []\n",
    "\n",
    "        for filename, label in file_list:\n",
    "            filepath = os.path.join(self.root_dir, filename)\n",
    "\n",
    "            # 提取MFCC特征\n",
    "            mfcc = self.mfcc_extractor.compute_mfcc(filepath)\n",
    "\n",
    "            # 转换为torch张量并存储\n",
    "            mfcc_tensor = torch.FloatTensor(mfcc)\n",
    "            label_tensor = torch.LongTensor([label])\n",
    "\n",
    "            data.append((mfcc_tensor, label_tensor))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 直接从内存中返回预处理好的数据\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class SpeechRecognizer(nn.Module):\n",
    "    def __init__(self, input_size=13, hidden_size=128, num_layers=2, num_classes=20):\n",
    "        super(SpeechRecognizer, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, features)\n",
    "        x, _ = self.lstm(x)\n",
    "        # 取最后一个时间步的输出\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6150bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化MFCC提取器\n",
    "mfcc_extractor = ManualMFCC(sample_rate=8000)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "VOCAB = {\"00\": \"数字\", \"01\": \"语音\", \"02\": \"语言\", \"03\": \"处理\", \"04\": \"中国\", \"05\": \"忠告\", \"06\": \"北京\", \"07\": \"背景\", \"08\": \"上海\", \"09\": \"商行\", \"10\": \"Speech\", \"11\": \"Speaker\", \"12\": \"Signal\", \"13\": \"Sequence\", \"14\": \"Processing\", \"15\": \"Print\", \"16\": \"Project\", \"17\": \"File\", \"18\": \"Open\", \"19\": \"Close\"}\n",
    "dataset = SpeechDataset(\"\", VOCAB, mfcc_extractor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = SpeechRecognizer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93e1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 3.01, Accuracy: 5.0%\n",
      "Epoch [2/100], Loss: 2.94, Accuracy: 13.0%\n",
      "Epoch [3/100], Loss: 2.70, Accuracy: 17.2%\n",
      "Epoch [4/100], Loss: 2.54, Accuracy: 19.2%\n",
      "Epoch [5/100], Loss: 2.36, Accuracy: 22.5%\n",
      "Epoch [6/100], Loss: 2.13, Accuracy: 30.2%\n",
      "Epoch [7/100], Loss: 1.89, Accuracy: 38.8%\n",
      "Epoch [8/100], Loss: 1.61, Accuracy: 54.8%\n",
      "Epoch [9/100], Loss: 1.44, Accuracy: 56.5%\n",
      "Epoch [10/100], Loss: 1.37, Accuracy: 61.2%\n",
      "Epoch [11/100], Loss: 1.14, Accuracy: 69.8%\n",
      "Epoch [12/100], Loss: 0.95, Accuracy: 77.2%\n",
      "Epoch [13/100], Loss: 0.82, Accuracy: 79.8%\n",
      "Epoch [14/100], Loss: 0.85, Accuracy: 77.8%\n",
      "Epoch [15/100], Loss: 0.66, Accuracy: 85.0%\n",
      "Epoch [16/100], Loss: 0.60, Accuracy: 87.2%\n",
      "Epoch [17/100], Loss: 0.56, Accuracy: 85.2%\n",
      "Epoch [18/100], Loss: 0.43, Accuracy: 91.8%\n",
      "Epoch [19/100], Loss: 0.35, Accuracy: 91.2%\n",
      "Epoch [20/100], Loss: 0.30, Accuracy: 93.5%\n",
      "Epoch [21/100], Loss: 0.29, Accuracy: 94.2%\n",
      "Epoch [22/100], Loss: 0.21, Accuracy: 96.0%\n",
      "Epoch [23/100], Loss: 0.19, Accuracy: 96.2%\n",
      "Epoch [24/100], Loss: 0.22, Accuracy: 96.2%\n",
      "Epoch [25/100], Loss: 0.21, Accuracy: 96.0%\n",
      "Epoch [26/100], Loss: 0.22, Accuracy: 96.5%\n",
      "Epoch [27/100], Loss: 0.20, Accuracy: 95.5%\n",
      "Epoch [28/100], Loss: 0.15, Accuracy: 97.8%\n",
      "Epoch [29/100], Loss: 0.12, Accuracy: 98.2%\n",
      "Epoch [30/100], Loss: 0.20, Accuracy: 95.8%\n",
      "Epoch [31/100], Loss: 0.11, Accuracy: 98.0%\n",
      "Epoch [32/100], Loss: 0.08, Accuracy: 99.5%\n",
      "Epoch [33/100], Loss: 0.07, Accuracy: 98.8%\n",
      "Epoch [34/100], Loss: 0.06, Accuracy: 98.8%\n",
      "Epoch [35/100], Loss: 0.06, Accuracy: 98.8%\n",
      "Epoch [36/100], Loss: 0.04, Accuracy: 99.8%\n",
      "Epoch [37/100], Loss: 0.03, Accuracy: 100.0%\n",
      "Epoch [38/100], Loss: 0.02, Accuracy: 100.0%\n",
      "Epoch [39/100], Loss: 0.02, Accuracy: 100.0%\n",
      "Epoch [40/100], Loss: 0.02, Accuracy: 100.0%\n",
      "Epoch [41/100], Loss: 0.02, Accuracy: 100.0%\n",
      "Epoch [42/100], Loss: 0.02, Accuracy: 99.8%\n",
      "Epoch [43/100], Loss: 0.02, Accuracy: 100.0%\n",
      "Epoch [44/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [45/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [46/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [47/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [48/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [49/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [50/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [51/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [52/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [53/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [54/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [55/100], Loss: 0.01, Accuracy: 99.8%\n",
      "Epoch [56/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [57/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [58/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [59/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [60/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [61/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [62/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [63/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [64/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [65/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [66/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [67/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [68/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [69/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [70/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [71/100], Loss: 0.01, Accuracy: 100.0%\n",
      "Epoch [72/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [73/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [74/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [75/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [76/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [77/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [78/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [79/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [80/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [81/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [82/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [83/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [84/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [85/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [86/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [87/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [88/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [89/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [90/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [91/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [92/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [93/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [94/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [95/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [96/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [97/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [98/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [99/100], Loss: 0.00, Accuracy: 100.0%\n",
      "Epoch [100/100], Loss: 0.00, Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (mfcc, labels) in enumerate(dataloader):\n",
    "        mfcc = mfcc.permute(0, 2, 1).to(device)  # (batch, time, features)\n",
    "        labels = labels.squeeze().to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(mfcc)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.2f}, Accuracy: {epoch_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65337ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果: 中国\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"21300240018/04/21300240018_04_03.dat\"\n",
    "\n",
    "mfcc_extractor = ManualMFCC()\n",
    "mfcc = mfcc_extractor.compute_mfcc(audio_file)\n",
    "\n",
    "mfcc_tensor = torch.FloatTensor(mfcc).unsqueeze(0).permute(0, 2, 1).to(device)  # (1, time, features)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(mfcc_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "predicted_idx = str(predicted.item()).zfill(2)\n",
    "print(\"预测结果:\", VOCAB[predicted_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2341f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10179fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
