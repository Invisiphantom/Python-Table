{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fdc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sorted_labels_eng = [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-MISC\", \"I-MISC\"]\n",
    "sorted_labels_chn = [\"O\", \"B-NAME\", \"M-NAME\", \"E-NAME\", \"S-NAME\", \"B-CONT\", \"M-CONT\", \"E-CONT\", \"S-CONT\", \"B-EDU\", \"M-EDU\", \"E-EDU\", \"S-EDU\", \"B-TITLE\", \"M-TITLE\", \"E-TITLE\", \"S-TITLE\", \"B-ORG\", \"M-ORG\", \"E-ORG\", \"S-ORG\", \"B-RACE\", \"M-RACE\", \"E-RACE\", \"S-RACE\", \"B-PRO\", \"M-PRO\", \"E-PRO\", \"S-PRO\", \"B-LOC\", \"M-LOC\", \"E-LOC\", \"S-LOC\"]\n",
    "\n",
    "\n",
    "def check(language, gold_path, my_path):\n",
    "    if language == \"English\":\n",
    "        sort_labels = sorted_labels_eng\n",
    "    else:\n",
    "        sort_labels = sorted_labels_chn\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with open(gold_path, \"r\") as g_f, open(my_path, \"r\") as m_f:\n",
    "        g_lines = g_f.readlines()\n",
    "        m_lines = m_f.readlines()\n",
    "        assert len(g_lines) == len(m_lines), \"Length is Not Equal.\"\n",
    "        for i in range(len(g_lines)):\n",
    "            if g_lines[i] == \"\\n\":\n",
    "                continue\n",
    "            g_word, g_tag = g_lines[i].strip().split(\" \")\n",
    "            m_word, m_tag = m_lines[i].strip().split(\" \")\n",
    "            y_true.append(g_tag)\n",
    "            y_pred.append(m_tag)\n",
    "    # print(f\"Micro F1 Score = {metrics.f1_score(y_true, y_pred, average='micro'):.4f}\")\n",
    "    print(metrics.classification_report(\n",
    "        y_true = y_true, y_pred=y_pred, labels=sort_labels[1:], digits=4\n",
    "    ))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5252e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9174    0.9804    0.9479       102\n",
      "      M-NAME     0.9136    0.9867    0.9487        75\n",
      "      E-NAME     0.9083    0.9706    0.9384       102\n",
      "      S-NAME     1.0000    0.5000    0.6667         8\n",
      "      B-CONT     0.8649    0.9697    0.9143        33\n",
      "      M-CONT     0.8750    0.9844    0.9265        64\n",
      "      E-CONT     0.8919    1.0000    0.9429        33\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.8333    0.9434    0.8850       106\n",
      "       M-EDU     0.8140    0.9887    0.8929       177\n",
      "       E-EDU     0.8739    0.9811    0.9244       106\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8214    0.8679    0.8440       689\n",
      "     M-TITLE     0.8189    0.9020    0.8584      1479\n",
      "     E-TITLE     0.9203    0.9724    0.9457       689\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8923    0.9368    0.9140       522\n",
      "       M-ORG     0.9202    0.9260    0.9231      3622\n",
      "       E-ORG     0.7832    0.8238    0.8030       522\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     0.9333    1.0000    0.9655        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     0.9333    1.0000    0.9655        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         1\n",
      "       B-PRO     0.5000    0.6667    0.5714        18\n",
      "       M-PRO     0.5385    0.6364    0.5833        33\n",
      "       E-PRO     0.6250    0.8333    0.7143        18\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.0000    0.0000    0.0000         2\n",
      "       M-LOC     0.0000    0.0000    0.0000         6\n",
      "       E-LOC     0.0000    0.0000    0.0000         2\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.8743    0.9168    0.8950      8437\n",
      "   macro avg     0.5493    0.5897    0.5649      8437\n",
      "weighted avg     0.8753    0.9168    0.8950      8437\n",
      "\n",
      "HMM-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.6667    0.0043    0.0086      1842\n",
      "       I-PER     0.0000    0.0000    0.0000      1307\n",
      "       B-ORG     0.1786    0.0037    0.0073      1341\n",
      "       I-ORG     0.8182    0.0120    0.0236       751\n",
      "       B-LOC     0.6364    0.0076    0.0151      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "\n",
      "   micro avg     0.4932    0.0042    0.0083      8603\n",
      "   macro avg     0.2875    0.0035    0.0068      8603\n",
      "weighted avg     0.3779    0.0042    0.0083      8603\n",
      "\n",
      "CRF-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.1358    0.1078    0.1202       102\n",
      "      M-NAME     0.0494    0.0533    0.0513        75\n",
      "      E-NAME     0.0494    0.0392    0.0437       102\n",
      "      S-NAME     0.0000    0.0000    0.0000         8\n",
      "      B-CONT     1.0000    0.0303    0.0588        33\n",
      "      M-CONT     1.0000    0.0312    0.0606        64\n",
      "      E-CONT     1.0000    0.0303    0.0588        33\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.9077    0.5566    0.6901       106\n",
      "       M-EDU     0.8545    0.7966    0.8246       177\n",
      "       E-EDU     0.8939    0.5566    0.6860       106\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8188    0.7213    0.7670       689\n",
      "     M-TITLE     0.8035    0.7410    0.7710      1479\n",
      "     E-TITLE     0.8970    0.7837    0.8366       689\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8524    0.7414    0.7930       522\n",
      "       M-ORG     0.7410    0.9188    0.8204      3622\n",
      "       E-ORG     0.7563    0.6360    0.6909       522\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     0.0000    0.0000    0.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     0.0000    0.0000    0.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         1\n",
      "       B-PRO     0.0000    0.0000    0.0000        18\n",
      "       M-PRO     0.0000    0.0000    0.0000        33\n",
      "       E-PRO     0.0000    0.0000    0.0000        18\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.0000    0.0000    0.0000         2\n",
      "       M-LOC     0.0000    0.0000    0.0000         6\n",
      "       E-LOC     0.0000    0.0000    0.0000         2\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7602    0.7659    0.7631      8437\n",
      "   macro avg     0.3362    0.2108    0.2273      8437\n",
      "weighted avg     0.7573    0.7659    0.7481      8437\n",
      "\n",
      "CRF-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.0198    0.0076    0.0110      1842\n",
      "       I-PER     0.0000    0.0000    0.0000      1307\n",
      "       B-ORG     0.0360    0.0075    0.0124      1341\n",
      "       I-ORG     0.0000    0.0000    0.0000       751\n",
      "       B-LOC     0.7750    0.0169    0.0330      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "\n",
      "   micro avg     0.0526    0.0064    0.0114      8603\n",
      "   macro avg     0.1039    0.0040    0.0070      8603\n",
      "weighted avg     0.1753    0.0064    0.0113      8603\n",
      "\n",
      "CRF_TF-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9417    0.9510    0.9463       102\n",
      "      M-NAME     0.8795    0.9733    0.9241        75\n",
      "      E-NAME     0.9245    0.9608    0.9423       102\n",
      "      S-NAME     0.7500    0.3750    0.5000         8\n",
      "      B-CONT     0.9697    0.9697    0.9697        33\n",
      "      M-CONT     1.0000    0.9688    0.9841        64\n",
      "      E-CONT     1.0000    1.0000    1.0000        33\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.7667    0.8679    0.8142       106\n",
      "       M-EDU     0.8947    0.9605    0.9264       177\n",
      "       E-EDU     0.8333    0.9434    0.8850       106\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.7803    0.7837    0.7820       689\n",
      "     M-TITLE     0.7698    0.8431    0.8048      1479\n",
      "     E-TITLE     0.9351    0.9405    0.9378       689\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8736    0.7548    0.8099       522\n",
      "       M-ORG     0.8187    0.9227    0.8676      3622\n",
      "       E-ORG     0.8326    0.7433    0.7854       522\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    1.0000    1.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    1.0000    1.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         1\n",
      "       B-PRO     0.3889    0.3889    0.3889        18\n",
      "       M-PRO     0.4667    0.2121    0.2917        33\n",
      "       E-PRO     0.3889    0.3889    0.3889        18\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.0000    0.0000    0.0000         2\n",
      "       M-LOC     0.0000    0.0000    0.0000         6\n",
      "       E-LOC     0.0000    0.0000    0.0000         2\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.8244    0.8733    0.8482      8437\n",
      "   macro avg     0.5380    0.5296    0.5297      8437\n",
      "weighted avg     0.8241    0.8733    0.8463      8437\n",
      "\n",
      "CRF_TF-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.0000    0.0000    0.0000      1842\n",
      "       I-PER     0.0000    0.0000    0.0000      1307\n",
      "       B-ORG     0.0000    0.0000    0.0000      1341\n",
      "       I-ORG     0.0000    0.0000    0.0000       751\n",
      "       B-LOC     0.0117    0.0207    0.0150      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "\n",
      "   micro avg     0.0117    0.0044    0.0064      8603\n",
      "   macro avg     0.0015    0.0026    0.0019      8603\n",
      "weighted avg     0.0025    0.0044    0.0032      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"HMM-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/validation.txt\", my_path=\"Chinese/validation_HMM.txt\")\n",
    "\n",
    "print(\"HMM-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/validation.txt\", my_path=\"English/validation_HMM.txt\")\n",
    "\n",
    "print(\"CRF-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/validation.txt\", my_path=\"Chinese/validation_CRF.txt\")\n",
    "\n",
    "print(\"CRF-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/validation.txt\", my_path=\"English/validation_CRF.txt\")\n",
    "\n",
    "print(\"CRF_TF-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/validation.txt\", my_path=\"Chinese/validation_CRF_TF.txt\")\n",
    "\n",
    "print(\"CRF_TF-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/validation.txt\", my_path=\"English/validation_CRF_TF.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f319679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9808    0.9107    0.9444       112\n",
      "      M-NAME     0.9753    0.9634    0.9693        82\n",
      "      E-NAME     0.9712    0.9018    0.9352       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     0.9333    1.0000    0.9655        28\n",
      "      M-CONT     0.9138    1.0000    0.9550        53\n",
      "      E-CONT     0.9333    1.0000    0.9655        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.8618    0.9464    0.9021       112\n",
      "       M-EDU     0.8390    0.9609    0.8958       179\n",
      "       E-EDU     0.9016    0.9821    0.9402       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8619    0.9000    0.8806       770\n",
      "     M-TITLE     0.8798    0.8881    0.8839      1921\n",
      "     E-TITLE     0.9316    0.9727    0.9517       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8918    0.9402    0.9153       552\n",
      "       M-ORG     0.9299    0.9474    0.9385      4312\n",
      "       E-ORG     0.8463    0.8877    0.8665       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     0.9333    1.0000    0.9655        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     0.9333    1.0000    0.9655        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.7188    0.6970    0.7077        33\n",
      "       M-PRO     0.5652    0.7647    0.6500        68\n",
      "       E-PRO     0.8182    0.8182    0.8182        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     1.0000    0.3333    0.5000         6\n",
      "       M-LOC     1.0000    0.2857    0.4444        21\n",
      "       E-LOC     1.0000    0.3333    0.5000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.9021    0.9263    0.9140      9890\n",
      "   macro avg     0.6444    0.6073    0.6082      9890\n",
      "weighted avg     0.9035    0.9263    0.9138      9890\n",
      "\n",
      "HMM-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.5833    0.0043    0.0086      1617\n",
      "       I-PER     0.0000    0.0000    0.0000      1156\n",
      "       B-ORG     0.4000    0.0072    0.0142      1661\n",
      "       I-ORG     0.7500    0.0036    0.0072       835\n",
      "       B-LOC     0.8571    0.0144    0.0283      1668\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     1.0000    0.0043    0.0085       702\n",
      "      I-MISC     0.0000    0.0000    0.0000       216\n",
      "\n",
      "   micro avg     0.6364    0.0060    0.0120      8112\n",
      "   macro avg     0.4488    0.0042    0.0083      8112\n",
      "weighted avg     0.5382    0.0060    0.0119      8112\n",
      "\n",
      "CRF-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.1852    0.1339    0.1554       112\n",
      "      M-NAME     0.0864    0.0854    0.0859        82\n",
      "      E-NAME     0.0864    0.0625    0.0725       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     1.0000    0.0357    0.0690        28\n",
      "      M-CONT     1.0000    0.0377    0.0727        53\n",
      "      E-CONT     1.0000    0.0357    0.0690        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.8235    0.5000    0.6222       112\n",
      "       M-EDU     0.7702    0.6927    0.7294       179\n",
      "       E-EDU     0.7419    0.4107    0.5287       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8584    0.7792    0.8169       770\n",
      "     M-TITLE     0.8148    0.7876    0.8010      1921\n",
      "     E-TITLE     0.8910    0.8065    0.8466       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8713    0.8098    0.8394       552\n",
      "       M-ORG     0.7928    0.9450    0.8623      4312\n",
      "       E-ORG     0.7929    0.7283    0.7592       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     0.0000    0.0000    0.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     0.0000    0.0000    0.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.0000    0.0000    0.0000        33\n",
      "       M-PRO     0.0000    0.0000    0.0000        68\n",
      "       E-PRO     0.0000    0.0000    0.0000        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.0000    0.0000    0.0000         6\n",
      "       M-LOC     0.0000    0.0000    0.0000        21\n",
      "       E-LOC     0.0000    0.0000    0.0000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7956    0.8005    0.7980      9890\n",
      "   macro avg     0.3348    0.2141    0.2291      9890\n",
      "weighted avg     0.7795    0.8005    0.7806      9890\n",
      "\n",
      "CRF-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.4400    0.0068    0.0134      1617\n",
      "       I-PER     0.0000    0.0000    0.0000      1156\n",
      "       B-ORG     0.0294    0.0006    0.0012      1661\n",
      "       I-ORG     0.0000    0.0000    0.0000       835\n",
      "       B-LOC     0.0000    0.0000    0.0000      1668\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       702\n",
      "      I-MISC     0.0000    0.0000    0.0000       216\n",
      "\n",
      "   micro avg     0.1818    0.0015    0.0029      8112\n",
      "   macro avg     0.0587    0.0009    0.0018      8112\n",
      "weighted avg     0.0937    0.0015    0.0029      8112\n",
      "\n",
      "CRF_TF-Chinese:               precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9434    0.8929    0.9174       112\n",
      "      M-NAME     0.9375    0.9146    0.9259        82\n",
      "      E-NAME     0.9252    0.8839    0.9041       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     0.9655    1.0000    0.9825        28\n",
      "      M-CONT     0.9815    1.0000    0.9907        53\n",
      "      E-CONT     0.9655    1.0000    0.9825        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.7798    0.7589    0.7692       112\n",
      "       M-EDU     0.8057    0.7877    0.7966       179\n",
      "       E-EDU     0.8636    0.8482    0.8559       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8048    0.8195    0.8121       770\n",
      "     M-TITLE     0.8412    0.8246    0.8328      1921\n",
      "     E-TITLE     0.9239    0.9455    0.9345       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8825    0.8025    0.8406       552\n",
      "       M-ORG     0.8509    0.9409    0.8936      4312\n",
      "       E-ORG     0.8288    0.7808    0.8041       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    0.9286    0.9630        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    0.9286    0.9630        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.4545    0.4545    0.4545        33\n",
      "       M-PRO     0.5417    0.3824    0.4483        68\n",
      "       E-PRO     0.5455    0.5455    0.5455        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.0000    0.0000    0.0000         6\n",
      "       M-LOC     0.0000    0.0000    0.0000        21\n",
      "       E-LOC     0.0000    0.0000    0.0000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.8506    0.8759    0.8631      9890\n",
      "   macro avg     0.5263    0.5137    0.5193      9890\n",
      "weighted avg     0.8472    0.8759    0.8603      9890\n",
      "\n",
      "CRF_TF-English:               precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.0100    0.0006    0.0012      1617\n",
      "       I-PER     0.0000    0.0000    0.0000      1156\n",
      "       B-ORG     0.0583    0.0108    0.0183      1661\n",
      "       I-ORG     0.0000    0.0000    0.0000       835\n",
      "       B-LOC     0.0000    0.0000    0.0000      1668\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0027    0.0128    0.0044       702\n",
      "      I-MISC     0.0000    0.0000    0.0000       216\n",
      "\n",
      "   micro avg     0.0074    0.0035    0.0047      8112\n",
      "   macro avg     0.0089    0.0030    0.0030      8112\n",
      "weighted avg     0.0142    0.0035    0.0044      8112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"HMM-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/chinese_test.txt\", my_path=\"Chinese/chinese_test_HMM.txt\")\n",
    "\n",
    "print(\"HMM-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/english_test.txt\", my_path=\"English/english_test_HMM.txt\")\n",
    "\n",
    "print(\"CRF-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/chinese_test.txt\", my_path=\"Chinese/chinese_test_CRF.txt\")\n",
    "\n",
    "print(\"CRF-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/english_test.txt\", my_path=\"English/english_test_CRF.txt\")\n",
    "\n",
    "print(\"CRF_TF-Chinese: \", end=\"\")\n",
    "check(language = \"Chinese\", gold_path=\"Chinese/chinese_test.txt\", my_path=\"Chinese/chinese_test_CRF_TF.txt\")\n",
    "\n",
    "print(\"CRF_TF-English: \", end=\"\")\n",
    "check(language = \"English\", gold_path=\"English/english_test.txt\", my_path=\"English/english_test_CRF_TF.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
